{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Build PNG Files\n",
    "\n",
    "### Basic Data Set\n",
    "In this notebook, we'll take the *`basic`* data set, use `ibmseti` Python package to convert each data file into a spectrogram, then save as `.png` files.\n",
    "\n",
    "### Split into training / test (cross-validation) and zip\n",
    "Also, we'll split the data set into a training set and a test set and create a handful of zip files for each class. This will dovetail into the next tutorial where we will train a custom Watson Visual Recognition classifier (we will use the zip files of pngs) and measure it's performance with the test (cross-validation) set. \n",
    "\n",
    "### Update for `primary`\n",
    "\n",
    "You may want to adapt this script to use the `primary` data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import cStringIO\n",
    "import glob\n",
    "import json\n",
    "import requests\n",
    "import ibmseti\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fbarilla/SETI/ML4SETI/tutorials/current_data\n"
     ]
    }
   ],
   "source": [
    "#Making a local folder to put my data.\n",
    "\n",
    "mydatafolder = os.environ['PWD'] + '/' + 'current_data'\n",
    "if os.path.exists(mydatafolder) is False:\n",
    "    os.makedirs(mydatafolder)\n",
    "print mydatafolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If you are running this in IBM Apache Spark (via Data Science Experience)\n",
    "base_url = 'https://dal05.objectstorage.service.networklayer.com/v1/AUTH_cdbef52bdf7a449c96936e1071f0a46b'\n",
    "\n",
    "#ELSE, if you are outside of IBM:\n",
    "base_url = 'https://dal.objectstorage.open.softlayer.com/v1/AUTH_cdbef52bdf7a449c96936e1071f0a46b'\n",
    "\n",
    "#NOTE: if you are outside of IBM, pulling down data will be slower. :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## You don't need to repeat this, of course, if you've already done this in the Step 1 notebook\n",
    "\n",
    "basic4zip = '{}/simsignals_basic_v2/basic4.zip'.format(base_url)\n",
    "os.system('curl {} > {}/{}'.format(basic4zip, mydatafolder, 'basic4.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls -alrht $mydatafolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputpng_folder = mydatafolder + '/png'\n",
    "if os.path.exists(outputpng_folder) is False:\n",
    "    os.makedirs(outputpng_folder)\n",
    "print outputpng_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use `ibmseti`, or other methods, to draw the spectrograms\n",
    "\n",
    "def draw_spectrogram(data):\n",
    "    \n",
    "    aca = ibmseti.compamp.SimCompamp(data)\n",
    "    spec = aca.get_spectrogram()\n",
    "\n",
    "    # Instead of using SimCompAmp.get_spectrogram method\n",
    "    # perform your own signal processing here before you create the spectrogram\n",
    "    #\n",
    "    # SimCompAmp.get_spectrogram is relatively simple. Here's the code to reproduce it:\n",
    "    #\n",
    "    # header, raw_data = r.content.split('\\n',1)\n",
    "    # complex_data = np.frombuffer(raw_data, dtype='i1').astype(np.float32).view(np.complex64)\n",
    "    # shape = (int(32*8), int(6144/8))\n",
    "    # spec = np.abs( np.fft.fftshift( np.fft.fft( complex_data.reshape(*shape) ), 1) )**2\n",
    "    # \n",
    "    # But instead of the line above, can you maniputlate `complex_data` with signal processing\n",
    "    # techniques in the time-domain (windowing?, de-chirp?), or manipulate the output of the \n",
    "    # np.fft.fft process in a way to improve the signal to noise (Welch periodogram, subtract noise model)? \n",
    "    # \n",
    "    # example: Apply Hanning Window\n",
    "    # complex_data = complex_data.reshape(*shape)\n",
    "    # complex_data = complex_data * np.hanning(complex_data.shape[1])\n",
    "    # spec = np.abs( np.fft.fftshift( np.fft.fft( complex_data ), 1) )**2\n",
    "    \n",
    "    # Alternatively:\n",
    "    # If you're using ibmseti 1.0.5 or greater, you can define a signal processing function,\n",
    "    # which will be passed the 2D complex-value time-series numpy array. Your processing function should return a 2D\n",
    "    # numpy array -- though it doesn't need to be complex-valued or even the same size.\n",
    "    # The SimCompamp.get_spectrogram function will treat the output of your signals processing function\n",
    "    # in the same way it treats the raw 2d complex-valued time-series data. \n",
    "    # The fourier transform of each row in the 2D array will be calculated\n",
    "    # and then squared to produce the spectrogram.\n",
    "    #\n",
    "    # def mySignalProcessing(compData):\n",
    "    #   return compData * np.hanning(compData.shape[1])\n",
    "    #\n",
    "    # aca.sigProc(mySignalProcessing)\n",
    "    # spc = aca.get_spectrogram()\n",
    "    #\n",
    "    # You can define more sophisticated signal processing inside your function.  \n",
    "    #\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))   \n",
    "\n",
    "    # do different color mappings affect Watson's classification accuracy?\n",
    "    # ax.imshow(np.log(spec), aspect = 0.5*float(spec.shape[1]) / spec.shape[0], cmap='hot')\n",
    "    # ax.imshow(np.log(spec), aspect = 0.5*float(spec.shape[1]) / spec.shape[0], cmap='gray')\n",
    "    # ax.imshow(np.log(spec), aspect = 0.5*float(spec.shape[1]) / spec.shape[0], cmap='Greys')\n",
    "    \n",
    "    # If you're going to plot the log, make sure there are no values less than or equal to zero \n",
    "    spec_pos_min = spec[spec > 0].min()\n",
    "    spec[spec <= 0] = spec_pos_min\n",
    "\n",
    "    ax.imshow(np.log(spec), aspect = 0.5*float(spec.shape[1]) / spec.shape[0], cmap='gray')\n",
    "    \n",
    "    return fig, aca.header()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().set(\"spark.ui.showConsoleProgress\", \"false\")\n",
    "sc = SparkContext(appName=\"PythonStatusAPIDemo\", conf=conf)\n",
    "\n",
    "## We're going to use Spark to distribute the job of creating the PNGs on the executor nodes\n",
    "myzipfilepath = os.path.join(mydatafolder,'basic4.zip')\n",
    "print myzipfilepath\n",
    "\n",
    "zz = zipfile.ZipFile(myzipfilepath)\n",
    "\n",
    "filenames = filter(lambda x: x.endswith('.dat'), zz.namelist())  #this filters out the top-level folder in the zip file, which is a separate entry in the namelist\n",
    "\n",
    "rdd = sc.parallelize(filenames, 8) #2 executors are available on free-tier IBM Spark clusters. If you have access to an Enterprise cluster, which has 30 executors, you should parallize to 120 partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_data(row):\n",
    "    zzz = zipfile.ZipFile(myzipfilepath)\n",
    "    return (row, zzz.open(row).read())\n",
    "\n",
    "rdd = rdd.map(extract_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_spectrogram_and_save(row):\n",
    "    name = os.path.basename(row[0])\n",
    "    fig, header = draw_spectrogram(row[1])\n",
    "    png_file = name + '.png'\n",
    "    fig.savefig(outputpng_folder + '/' + png_file)\n",
    "    plt.close(fig)\n",
    "    return (name, header, png_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = rdd.map(convert_to_spectrogram_and_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = rdd.collect()  #This took about 70s on an Enterprise cluster. It will take longer on your free-tier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('000919a5-bc7f-471e-959c-81adba0b1f36.dat',\n",
       " {u'signal_classification': u'squiggle',\n",
       "  u'uuid': u'000919a5-bc7f-471e-959c-81adba0b1f36'},\n",
       " '000919a5-bc7f-471e-959c-81adba0b1f36.dat.png')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training / Test sets\n",
    "\n",
    "Using the `basic` list, we'll create training and test sets for each signal class. Then we'll archive the `.png` files into a handful of `.zip` files (We need the .zip files to be smaller than 100 MB because there is a limitation with the size of batches of data that are uploaded to Watson Visual Recognition when training a classifier.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 4000 files\n"
     ]
    }
   ],
   "source": [
    "# Grab the Basic file list in order to \n",
    "# Organize the Data into classes\n",
    "\n",
    "r = requests.get('{}/simsignals_files/public_list_basic_v2_26may_2017.csv'.format(base_url), timeout=(9.0, 21.0))\n",
    "\n",
    "uuids_classes_as_list = r.text.split('\\n')[1:-1]  #slice off the first line (header) and last line (empty)\n",
    "\n",
    "def row_to_json(row):\n",
    "    uuid,sigclass = row.split(',')\n",
    "    return {'uuid':uuid, 'signal_classification':sigclass}\n",
    "\n",
    "uuids_classes_as_list = map(lambda row: row_to_json(row), uuids_classes_as_list)\n",
    "print \"found {} files\".format(len(uuids_classes_as_list))\n",
    "\n",
    "uuids_group_by_class = {}\n",
    "for item in uuids_classes_as_list:\n",
    "    uuids_group_by_class.setdefault(item['signal_classification'], []).append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squiggle: training set size: 200\n",
      "squiggle: test set size: 100\n",
      "narrowband: training set size: 200\n",
      "narrowband: test set size: 100\n",
      "noise: training set size: 200\n",
      "noise: test set size: 100\n",
      "narrowbanddrd: training set size: 200\n",
      "narrowbanddrd: test set size: 100\n"
     ]
    }
   ],
   "source": [
    "#At first, use just 20 percent and 10 percent. This will be useful \n",
    "#as you prototype. Then you can come back here and increase these\n",
    "#percentages as needed.\n",
    "\n",
    "training_percentage = 0.20\n",
    "test_percentage = 0.10\n",
    "\n",
    "assert training_percentage + test_percentage <= 1.0\n",
    "\n",
    "training_set_group_by_class = {}\n",
    "test_set_group_by_class = {}\n",
    "for k, v in uuids_group_by_class.iteritems():\n",
    "    \n",
    "    total = len(v)\n",
    "    training_size = int(total * training_percentage)\n",
    "    test_size = int(total * test_percentage)\n",
    "    \n",
    "    training_set = v[:training_size]\n",
    "    test_set = v[-1*test_size:]\n",
    "    \n",
    "    training_set_group_by_class[k] = training_set\n",
    "    test_set_group_by_class[k] = test_set\n",
    "    \n",
    "    print '{}: training set size: {}'.format(k, len(training_set))\n",
    "    print '{}: test set size: {}'.format(k, len(test_set))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signal_classification': u'noise',\n",
       " 'uuid': u'498becc2-3693-45b3-8533-50e93532706a'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_group_by_class['noise'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fnames = [outputpng_folder + '/' + vv['uuid'] + '.dat.png' for vv in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zipfilefolder = mydatafolder + '/zipfiles'\n",
    "if os.path.exists(zipfilefolder) is False:\n",
    "    os.makedirs(zipfilefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_zip_file_size_in_mb = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_1_squiggle.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_2_squiggle.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_3_squiggle.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_1_narrowband.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_2_narrowband.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_3_narrowband.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_4_narrowband.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_1_noise.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_2_noise.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_3_noise.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_4_noise.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_1_narrowbanddrd.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_2_narrowbanddrd.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_3_narrowbanddrd.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/classification_4_narrowbanddrd.zip\n"
     ]
    }
   ],
   "source": [
    "#Create the Zip files containing the training PNG files\n",
    "#Note that this limits output files to be less than <max_zip_file_size_in_mb> MB because WatsonVR has a limit on the \n",
    "#size of input files that can be sent in single HTTP calls to train a custom classifier\n",
    "\n",
    "for k, v, in training_set_group_by_class.iteritems():\n",
    "    \n",
    "    fnames = [outputpng_folder + '/' + vv['uuid'] + '.dat.png' for vv in v]  #yes, files are <uuid>.dat.png :/\n",
    "    \n",
    "    count = 1\n",
    "    for fn in fnames:\n",
    "        \n",
    "        archive_name = '{}/classification_{}_{}.zip'.format(zipfilefolder, count, k)\n",
    "        \n",
    "        if os.path.exists(archive_name):\n",
    "            zz = zipfile.ZipFile(archive_name, mode='a')\n",
    "        else:\n",
    "            print 'creating new archive', archive_name\n",
    "            zz = zipfile.ZipFile(archive_name, mode='w')\n",
    "           \n",
    "        zz.write(fn)\n",
    "        zz.close()\n",
    "        \n",
    "        #if archive_name folder exceeds <max_zip_file_size_in_mb> MB, increase count to create a new one\n",
    "        if os.path.getsize(archive_name) > max_zip_file_size_in_mb * 1024 ** 2:\n",
    "            count += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_1_squiggle.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_2_squiggle.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_3_squiggle.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_4_squiggle.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_5_squiggle.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_6_squiggle.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_7_squiggle.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_8_squiggle.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_1_narrowband.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_2_narrowband.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_3_narrowband.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_4_narrowband.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_5_narrowband.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_6_narrowband.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_7_narrowband.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_8_narrowband.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_1_noise.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_2_noise.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_3_noise.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_4_noise.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_5_noise.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_6_noise.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_7_noise.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_8_noise.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_9_noise.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_1_narrowbanddrd.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_2_narrowbanddrd.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_3_narrowbanddrd.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_4_narrowbanddrd.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_5_narrowbanddrd.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_6_narrowbanddrd.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_7_narrowbanddrd.zip\n",
      "creating new archive /home/fbarilla/SETI/ML4SETI/tutorials/current_data/zipfiles/testset_8_narrowbanddrd.zip\n"
     ]
    }
   ],
   "source": [
    "# Create the Zip files containing the test PNG files using the following naming convention:\n",
    "# testset_<NUMBER>_<CLASS>.zip (The next notebook example using Watson will break if a \n",
    "# different naming convention is used) Refer to \n",
    "# https://www.ibm.com/watson/developercloud/visual-recognition/api/v3/#classify_an_image \n",
    "# for ZIP size and content limitations:\n",
    "# \"The max number of images in a .zip file is limited to 20, and limited to 5 MB.\"\n",
    "\n",
    "for k, v, in test_set_group_by_class.iteritems():\n",
    "    \n",
    "    fnames = [outputpng_folder + '/' + vv['uuid'] + '.dat.png' for vv in v]  #yes, files are <uuid>.dat.png :/\n",
    "    \n",
    "    count = 1\n",
    "    img_count = 0\n",
    "    for fn in fnames:\n",
    "        \n",
    "        archive_name = '{}/testset_{}_{}.zip'.format(zipfilefolder, count, k)\n",
    "        \n",
    "        if os.path.exists(archive_name):\n",
    "            zz = zipfile.ZipFile(archive_name, mode='a')\n",
    "        else:\n",
    "            print 'creating new archive', archive_name\n",
    "            zz = zipfile.ZipFile(archive_name, mode='w')\n",
    "           \n",
    "        zz.write(fn)\n",
    "        zz.close()\n",
    "        img_count += 1\n",
    "        #if archive_name folder exceeds 5 MB or there are more than 20 images, \n",
    "        # increase count to create a new one\n",
    "        if (os.path.getsize(archive_name) >= 4.7 * 1024 ** 2) or img_count == 20:\n",
    "            count += 1\n",
    "            img_count = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 459M\r\n",
      "drwxrwxr-x 4 fbarilla fbarilla 4.0K Jul 31 17:01 ..\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla  26M Jul 31 17:01 classification_1_squiggle.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla  26M Jul 31 17:01 classification_2_squiggle.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla  26M Jul 31 17:01 classification_3_squiggle.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla  26M Jul 31 17:01 classification_1_narrowband.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla  26M Jul 31 17:01 classification_2_narrowband.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla  26M Jul 31 17:01 classification_3_narrowband.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 788K Jul 31 17:01 classification_4_narrowband.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla  26M Jul 31 17:01 classification_1_noise.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla  26M Jul 31 17:01 classification_2_noise.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla  26M Jul 31 17:01 classification_3_noise.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 2.8M Jul 31 17:01 classification_4_noise.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla  26M Jul 31 17:01 classification_1_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla  26M Jul 31 17:01 classification_2_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla  26M Jul 31 17:01 classification_3_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 401K Jul 31 17:01 classification_4_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.0M Jul 31 17:02 testset_1_squiggle.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.9M Jul 31 17:02 testset_2_squiggle.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.0M Jul 31 17:02 testset_3_squiggle.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.9M Jul 31 17:02 testset_4_squiggle.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.9M Jul 31 17:02 testset_5_squiggle.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.9M Jul 31 17:02 testset_6_squiggle.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.0M Jul 31 17:02 testset_7_squiggle.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 3.4M Jul 31 17:02 testset_8_squiggle.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.0M Jul 31 17:02 testset_1_narrowband.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.0M Jul 31 17:02 testset_2_narrowband.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.0M Jul 31 17:02 testset_3_narrowband.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.9M Jul 31 17:02 testset_4_narrowband.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.0M Jul 31 17:02 testset_5_narrowband.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.9M Jul 31 17:02 testset_6_narrowband.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.0M Jul 31 17:02 testset_7_narrowband.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 3.5M Jul 31 17:02 testset_8_narrowband.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.8M Jul 31 17:02 testset_1_noise.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.8M Jul 31 17:02 testset_2_noise.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.8M Jul 31 17:02 testset_3_noise.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.1M Jul 31 17:02 testset_4_noise.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.8M Jul 31 17:02 testset_5_noise.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.8M Jul 31 17:02 testset_6_noise.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.1M Jul 31 17:02 testset_7_noise.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.8M Jul 31 17:02 testset_8_noise.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 820K Jul 31 17:02 testset_9_noise.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.0M Jul 31 17:02 testset_1_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.0M Jul 31 17:02 testset_2_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.9M Jul 31 17:02 testset_3_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.0M Jul 31 17:02 testset_4_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 4.9M Jul 31 17:02 testset_5_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.0M Jul 31 17:02 testset_6_narrowbanddrd.zip\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 5.0M Jul 31 17:02 testset_7_narrowbanddrd.zip\r\n",
      "drwxrwxr-x 2 fbarilla fbarilla 4.0K Jul 31 17:02 .\r\n",
      "-rw-rw-r-- 1 fbarilla fbarilla 3.5M Jul 31 17:02 testset_8_narrowbanddrd.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alrth $mydatafolder/zipfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting your Zip files\n",
    "\n",
    "If you've been running this on an IBM DSX Spark cluster and you wish to move your data from the local filespace, the easiest and fastest way is to push these PNG files to an IBM Object Storage account. An Object Storage instances was created for you when you signed up for DSX. \n",
    "\n",
    "You do NOT need to do this if you're going on to the next notebook where you use Watson to classify your images from this Spark cluster. That notebook will read the data from the local file space.\n",
    "\n",
    "\n",
    "### Get your Object Storage Credentials\n",
    "1. Log in to https://bluemix.net\n",
    "2. Scroll down and find your Object Storage instance. \n",
    "  * If you do not have one, find the \"Catalog\" link and look for the Object Storage service to create a new instance (5 GB of free space)\n",
    "3. Select the `Service Credentials` tab and `View Credentials`\n",
    "4. Copy these into your notebook below.\n",
    "\n",
    "### Create a Container\n",
    "5. CREATE A CONTAINER in your Object Storage that you will use below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import swiftclient.client as swiftclient\n",
    "\n",
    "credentials = {\n",
    "  'auth_uri':'',\n",
    "  'global_account_auth_uri':'',\n",
    "  'username':'xx',\n",
    "  'password':\"xx\",\n",
    "  'auth_url':'https://identity.open.softlayer.com',\n",
    "  'project':'xx',\n",
    "  'projectId':'xx',\n",
    "  'region':'dallas',\n",
    "  'userId':'xx',\n",
    "  'domain_id':'xx',\n",
    "  'domain_name':'xx',\n",
    "  'tenantId':'xx'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn_seti_data = swiftclient.Connection(\n",
    "    key=creds_seti_public['password'],\n",
    "    authurl=creds_seti_public['auth_url']+\"/v3\",\n",
    "    auth_version='3',\n",
    "    os_options={\n",
    "        \"project_id\": creds_seti_public['projectId'],\n",
    "        \"user_id\": creds_seti_public['userId'],\n",
    "        \"region_name\": creds_seti_public['region']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myObjectStorageContainer = 'seti_pngs'  \n",
    "someFile = os.path.join(zipfilefolder, 'classification_1_narrowband.zip')\n",
    "\n",
    "etag = conn_seti_data.put_object(myObjectStorageContainer, someFile, open(someFile,'rb').read())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
